# YuYing-Chameleon 项目运行逻辑说明文档

## 📖 目录
1. [项目简介](#项目简介)
2. [整体架构](#整体架构)
3. [核心概念与术语](#核心概念与术语)
4. [启动流程](#启动流程)
5. [消息处理完整流程](#消息处理完整流程)
6. [数据库结构说明](#数据库结构说明)
7. [关键模块详解](#关键模块详解)
8. [配置说明](#配置说明)
9. [常见问题](#常见问题)

---

## 项目简介

### 这是什么?
YuYing-Chameleon 是一个基于 NoneBot2 的智能QQ机器人,具有以下核心功能:
- **上下文理解**: 通过向量检索和记忆系统理解对话上下文
- **长期记忆**: 自动提取并保存用户的个人信息、偏好、习惯
- **对话摘要**: 自动生成对话窗口摘要,节省LLM上下文
- **表情包系统**: 自动收集、管理和智能发送表情包
- **频率控制**: 防止刷屏,模拟真人回复节奏

### 技术栈
- **框架**: NoneBot2 (异步Python机器人框架)
- **适配器**: OneBot V11 (QQ协议)
- **数据库**: SQLite + SQLAlchemy (ORM)
- **向量库**: Qdrant (向量检索)
- **LLM**: OpenAI兼容API (支持多种LLM)
- **Embedding**: 文本向量化模型

---

## 整体架构

### 分层架构图

```
┌──────────────────────────────────────────────────────────────────┐
│                        用户交互层 (QQ)                             │
└───────────────────────────┬──────────────────────────────────────┘
                            │
┌───────────────────────────▼──────────────────────────────────────┐
│                    NoneBot2 事件层                                │
│              (OneBot V11 Adapter)                                │
└───────────────────────────┬──────────────────────────────────────┘
                            │
┌───────────────────────────▼──────────────────────────────────────┐
│                      主入口 (__init__.py)                        │
│              消息接收 → 解析 → 处理 → 回复                         │
└─┬─────────────────────────────────────────────────────────────┬──┘
  │                                                             │
  ├─────────────────────┬───────────────────────────────────────┤
  │                     │                                       │
  ▼                     ▼                                       ▼
┌──────────────┐  ┌────────────────┐                  ┌──────────────┐
│  消息解析层  │  │   策略层       │                  │  动作规划层  │
│              │  │                │                  │              │
│ - Lagrange   │  │ - Gatekeeper   │                  │ - Planner    │
│   Parser     │  │   (回复策略)    │                  │ - Sender     │
│ - Normalizer │  │                │                  │              │
└──────┬───────┘  └────────┬───────┘                  └──────┬───────┘
       │                   │                                 │
       │                   │                                 │
  ┌────▼───────────────────▼─────────────────────────────────▼────┐
  │                    业务能力层                                  │
  │                                                                │
  │  ┌──────────┐  ┌─────────┐  ┌───────┐  ┌──────────┐         │
  │  │ Retrieval│  │ Memory  │  │Summary│  │ Stickers │         │
  │  │  (检索)  │  │ (记忆)  │  │(摘要) │  │(表情包)  │         │
  │  └──────────┘  └─────────┘  └───────┘  └──────────┘         │
  └────────────────────────────┬─────────────────────────────────┘
                               │
  ┌────────────────────────────▼─────────────────────────────────┐
  │                      外部服务层                               │
  │                                                               │
  │  ┌────────┐        ┌──────────┐       ┌──────────┐          │
  │  │  LLM   │        │  Qdrant  │       │ Embedder │          │
  │  │ Client │        │  Vector  │       │          │          │
  │  └────────┘        └──────────┘       └──────────┘          │
  └────────────────────────────┬─────────────────────────────────┘
                               │
  ┌────────────────────────────▼─────────────────────────────────┐
  │                      存储层                                    │
  │                                                               │
  │  ┌──────────────┐          ┌──────────────┐                  │
  │  │   SQLite     │          │   Workers    │                  │
  │  │  (数据库)     │          │  (后台任务)   │                  │
  │  │              │          │              │                  │
  │  │  - Models    │          │  - Index     │                  │
  │  │  - Repos     │          │  - Media     │                  │
  │  │  - DBWriter  │          │  - Sticker   │                  │
  │  └──────────────┘          └──────────────┘                  │
  └──────────────────────────────────────────────────────────────┘
```

### 模块职责一览表

| 模块 | 职责 | 输入 | 输出 |
|-----|------|-----|-----|
| **Lagrange Parser** | 解析NoneBot事件为内部格式 | OneBot Event | InboundMessage |
| **Normalizer** | 消息归一化(处理图片、@等) | InboundMessage | NormalizedMessage |
| **Gatekeeper** | 决定是否回复(频率控制) | 消息+场景 | bool (是否回复) |
| **Retriever** | 检索相关上下文 | 查询文本 | 检索结果列表 |
| **Memory Manager** | 管理用户记忆 | 用户ID | 记忆列表 |
| **Summary Manager** | 生成对话摘要 | 消息窗口 | 摘要文本 |
| **Action Planner** | 规划回复动作 | 上下文+用户消息 | 动作列表 |
| **Action Sender** | 执行发送动作 | 动作列表 | 发送结果 |
| **Sticker Selector** | 选择合适表情包 | 对话意图 | 表情包ID |
| **DB Writer** | 异步写库队列 | 写入任务 | 无 |
| **Workers** | 后台任务处理 | 任务队列 | 处理结果 |

---

## 核心概念与术语

### 小白必读:关键术语解释

#### 1. 场景 (Scene)
- **scene_type**: 场景类型,只有两种值:
  - `"group"`: 群聊
  - `"private"`: 私聊
- **scene_id**: 场景的唯一标识
  - 群聊时是群号
  - 私聊时是对方的QQ号

#### 2. 消息类型
- **原始消息**: 从QQ收到的原始事件,包含各种复杂字段
- **归一化消息**: 经过处理统一格式后的消息,便于后续处理
- **有效消息**: 非纯表情、非纯空格的正常对话,才会计入统计

#### 3. 记忆系统
- **提取**: 从聊天记录中提取用户信息(如"喜欢吃辣")
- **浓缩**: 将多条旧记忆合并成更简洁的新记忆
- **分层**:
  - `active`: 活跃记忆(常用)
  - `archive`: 归档记忆(较久未用)
  - `core`: 核心记忆(永久保留)

#### 4. 向量检索 (RAG - 检索增强生成)
- **Embedding**: 将文本转为数字向量(一串数字)
- **向量相似度**: 两段文本的意思越接近,向量越相似
- **top-k检索**: 找出最相似的前k条记录
- **Qdrant**: 专门存储和检索向量的数据库

#### 5. 表情包系统
- **偷取**: 从群聊中自动收集图片作为表情包候选
- **候选池**: 临时存放可能的表情包,多次出现后才正式收录
- **晋升**: 候选表情包达到使用次数阈值,加入正式表情包库
- **意图匹配**: 根据对话意图(如"无奈"、"开心")选择合适表情

#### 6. 摘要窗口
- **窗口**: 一段时间或一定条数的消息范围
- **滚动**: 新窗口覆盖旧窗口,保持最新的对话摘要
- **用途**: 压缩大量消息为简短摘要,节省LLM上下文长度

#### 7. 异步与并发
- **异步 (async/await)**: 一个任务等待时,可以去做别的任务,提高效率
- **后台任务 (Worker)**: 不影响主流程的耗时任务,放到后台慢慢处理
- **队列**: 任务排队等待处理,先进先出

---

## 启动流程

### 完整启动步骤详解

```
用户执行: nb run
    │
    ├─→ NoneBot加载插件(__init__.py)
    │       │
    │       ├─→ 导入配置(config.py)
    │       │       ├─→ 读取环境变量
    │       │       ├─→ 读取config.toml
    │       │       ├─→ 合并配置
    │       │       └─→ 初始化plugin_config全局对象
    │       │
    │       └─→ 执行@driver.on_startup装饰的startup()函数
    │
    ├─→ 1️⃣ 初始化数据库
    │       ├─→ 执行run_migrations() (数据库迁移)
    │       │   失败则回退到Base.metadata.create_all()
    │       └─→ 创建所有表(如果不存在)
    │
    ├─→ 2️⃣ 初始化向量库
    │       ├─→ 连接Qdrant服务
    │       ├─→ 创建collections(消息、记忆、表情包)
    │       └─→ 如果配置了recreate,则删除旧数据重建
    │
    ├─→ 3️⃣ 启动写入队列
    │       └─→ asyncio.create_task(db_writer.run_forever())
    │           启动一个永久运行的后台任务,处理写库请求
    │
    ├─→ 4️⃣ 启动后台Workers
    │       ├─→ index_worker: 处理向量索引任务
    │       ├─→ media_worker: 处理图片OCR/caption任务
    │       └─→ sticker_worker: 处理表情包候选晋升
    │
    ├─→ 5️⃣ 扫描本地表情包
    │       ├─→ 读取assets/stickers目录
    │       ├─→ 计算图片哈希和指纹
    │       └─→ 导入到数据库
    │
    ├─→ 6️⃣ 初始化定时任务
    │       └─→ 注册APScheduler任务
    │           ├─→ 每天凌晨3点: 记忆浓缩任务
    │           ├─→ 每小时: 清理过期数据
    │           └─→ 每天: 统计任务
    │
    └─→ ✅ 启动完成,开始监听消息
```

### 启动失败处理

如果启动过程中出错:
1. **数据库失败**: 程序会退出,需检查database_url配置和权限
2. **Qdrant失败**: 只记录警告,允许降级运行(不使用向量检索)
3. **表情包扫描失败**: 只记录警告,继续启动
4. **Workers启动失败**: 只记录错误,主功能仍可用

---

## 消息处理完整流程

### 从收到消息到发送回复的全过程

```
📱 QQ用户发送消息
    │
    ▼
┌────────────────────────────────────────────────────────┐
│ 步骤1: 事件接收与解析                                    │
│                                                        │
│ OneBot协议 → NoneBot事件 → LagrangeParser.parse_event  │
│                                                        │
│ 输入: NoneBot Event对象                                 │
│ 输出: InboundMessage {                                  │
│   qq_id: 发送者QQ号                                     │
│   message_type: "group" 或 "private"                   │
│   scene_id: 群号或QQ号                                  │
│   raw_message: 原始消息对象                              │
│   ...                                                  │
│ }                                                      │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤2: 消息归一化                                        │
│                                                        │
│ Normalizer.normalize(inbound)                          │
│                                                        │
│ 处理内容:                                               │
│ • 提取纯文本内容                                        │
│ • 识别图片,替换为[image:xxx]占位符                       │
│ • 解析@机器人,设置mentioned_bot=True                     │
│ • 解析引用回复,提取reply_to_msg_id                       │
│ • 判断是否"有效消息"(非纯表情/空格)                       │
│                                                        │
│ 输出: NormalizedMessage {                               │
│   content: "归一化后的文本内容"                          │
│   image_ref_map: {raw_ref: media_key}                  │
│   mentioned_bot: True/False                            │
│   is_effective: True/False                             │
│   ...                                                  │
│ }                                                      │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤3: 写入原始消息表 (高优先级直写)                      │
│                                                        │
│ RawRepository.add(RawMessage)                          │
│                                                        │
│ • 所有消息都会记录到raw_messages表                       │
│ • 包括机器人自己发的消息(is_bot=True)                    │
│ • 用于历史追溯、记忆提取、摘要生成                        │
│                                                        │
│ 返回: raw_msg (带有自增ID的消息对象)                     │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤4: 图片预处理任务创建 (如果消息包含图片)              │
│                                                        │
│ 对每张图片:                                             │
│ ├─→ 创建OCR任务 → IndexJob(item_type="ocr")            │
│ │   • 后台media_worker会处理                           │
│ │   • 提取图片中的文字                                  │
│ │   • 生成图片说明(caption)                            │
│ │                                                     │
│ └─→ (仅群聊) 表情包偷取                                 │
│     • 下载图片到临时目录                                │
│     • 异步调用StickerStealer.process_image()           │
│     • 计算指纹,加入候选池                               │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤5: 创建消息索引任务                                  │
│                                                        │
│ IndexJob(item_type="msg_chunk", ref_id=raw_msg.id)    │
│                                                        │
│ • 后台index_worker会处理                                │
│ • 生成消息的Embedding向量                               │
│ • 写入Qdrant向量库                                      │
│ • 用于后续的语义检索                                     │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤6: 推进摘要窗口                                      │
│                                                        │
│ SummaryManager.on_message()                            │
│                                                        │
│ • 检查当前窗口消息数是否达到阈值(默认20条)               │
│ • 或时间窗口是否超时(默认15分钟)                         │
│ • 如果达到,调用LLM生成摘要                              │
│ • 摘要存入summaries表                                   │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤7: 有效消息计数与记忆触发 (仅有效消息)               │
│                                                        │
│ if normalized.is_effective:                            │
│   ├─→ ProfileRepository.increment_effective_count()    │
│   │   用户的effective_count加1                         │
│   │                                                    │
│   ├─→ MemoryManager.mark_pending_if_needed()          │
│   │   如果count达到next_memory_at阈值:                 │
│   │   • 设置pending_memory=True                       │
│   │   • 后台会在空闲时提取记忆                          │
│   │                                                    │
│   └─→ MemoryManager.schedule_idle_extract()           │
│       设置空闲计时器(默认2分钟)                          │
│       对话停止后自动提取记忆                             │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤8: 策略判断 - 是否需要回复?                          │
│                                                        │
│ 提前获取图片信息(用于心流模式和后续规划):               │
│ image_inputs = _collect_image_inputs()                │
│ • 避免重复调用bot.get_image()                          │
│ • 提供图片URL供多模态判断使用                           │
│                                                        │
│ should_reply = Gatekeeper.should_reply(               │
│     ..., image_inputs=image_inputs                    │
│ )                                                      │
│                                                        │
│ ==================== 模式选择 ====================      │
│                                                        │
│ 🔹 传统模式 (flow_mode_enabled=false):                 │
│   判断条件(任一满足即回复):                             │
│   ✓ 私聊消息 (默认必回)                                 │
│   ✓ 群聊中@了机器人                                     │
│   ✓ 群聊中按概率随机回复(默认15%)                       │
│                                                        │
│   限流检查(满足则跳过回复):                             │
│   ✗ 全局冷却中 (距离上次回复<30秒)                      │
│   ✗ 场景冷却中 (本群<60秒内已回复)                      │
│   ✗ 检测到刷屏 (30秒内>12条消息)                       │
│                                                        │
│ 🔹 心流模式 (flow_mode_enabled=true):                  │
│   使用nano模型智能决策是否回复                          │
│                                                        │
│   决策流程:                                             │
│   1️⃣ 冷却检查 → 冷却中直接不回                         │
│   2️⃣ directed_to_bot → 必回(受冷却)                   │
│   3️⃣ 短路规则:                                         │
│      • 纯表情/emoji → 不回                             │
│      • 过短消息(<3字符) → 不回                         │
│      • 明显提问(含"吗"/"?"等) → 回                     │
│   4️⃣ 概率抽样 → 决定是否调用nano                       │
│   5️⃣ nano模型判断:                                     │
│      • 获取最近10条对话上下文                           │
│      • 🎨 多模态支持: 如果有图片,以OpenAI格式发送      │
│      • nano返回yes/no决策                              │
│                                                        │
│   多模态消息格式:                                       │
│   {                                                    │
│     "role": "user",                                   │
│     "content": [                                      │
│       {"type": "text", "text": "..."},               │
│       {"type": "image_url",                          │
│        "image_url": {"url": "https://..."}},        │
│       {"type": "text",                               │
│        "text": "image_caption: ..."}                │
│     ]                                                 │
│   }                                                    │
│                                                        │
│   优势:                                                 │
│   • 理解对话语境,智能判断参与时机                       │
│   • 支持视觉理解,可根据图片内容决策                     │
│   • 避免无意义回复,提升对话质量                         │
│   • 并发控制(Semaphore限制3个并发)                     │
│                                                        │
│ 如果should_reply=False且未@机器人:                      │
│   └─→ 直接返回,不回复                                   │
└────────────┬───────────────────────────────────────────┘
             │ should_reply=True
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤9: 补全图片说明 (如果需要回复且有图片)               │
│                                                        │
│ 对当前消息中的图片:                                      │
│ ├─→ 检查MediaCache是否已有caption                      │
│ │   有 → 直接使用                                       │
│ │   无 ↓                                               │
│ └─→ 同步调用VisionHelper生成caption和OCR               │
│     • 调用视觉模型(支持图像输入的LLM)                    │
│     • 生成图片描述                                       │
│     • 识别图中文字(如果启用OCR)                          │
│     • 更新消息content,将[image:xxx]替换为              │
│       [image:xxx:图片说明前20字...]                     │
│     • 写入MediaCache缓存                               │
│                                                        │
│ 目的: 让LLM能"看懂"图片内容                             │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤10: 检索相关上下文                                   │
│                                                        │
│ Retriever.build_hybrid_query()                         │
│ • 构建混合查询(用户消息 + 用户信息)                      │
│                                                        │
│ Retriever.retrieve()                                   │
│ ├─→ 向量检索 (Qdrant)                                  │
│ │   • 生成查询文本的Embedding                           │
│ │   • 在向量库中搜索最相似的top-k条消息                  │
│ │   • 返回相关的历史消息片段                             │
│ │                                                      │
│ ├─→ 记忆检索 (Memory)                                  │
│ │   • 获取用户的活跃记忆(active)                        │
│ │   • 获取核心记忆(core)                                │
│ │   • 按置信度和相关性排序                              │
│ │                                                      │
│ └─→ 摘要检索 (Summary)                                 │
│     • 获取最近的对话摘要                                │
│     • 提供对话历史概览                                  │
│                                                        │
│ 输出: context = {                                       │
│   "memories": [记忆列表],                               │
│   "rag_snippets": [检索到的相关片段],                    │
│   "summary": "最近对话摘要"                             │
│ }                                                      │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤11: 构建最近对话历史                                 │
│                                                        │
│ _build_recent_dialogue()                               │
│                                                        │
│ • 从raw_messages获取最近10条消息                        │
│ • 格式化为对话列表:                                      │
│   ["我: 今天天气真好",                                   │
│    "群友(123): 是啊",                                   │
│    "你: 要不要出去玩"]                                   │
│ • 用于LLM理解immediate context                          │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤12: 动作规划 (核心 - 调用LLM)                       │
│                                                        │
│ ActionPlanner.plan_actions()                           │
│                                                        │
│ 输入准备:                                               │
│ • 用户当前消息                                           │
│ • 记忆列表(用户是谁、喜好等)                             │
│ • 检索片段(相关历史)                                     │
│ • 最近对话历史                                           │
│ • 图片信息(如果有)                                       │
│                                                        │
│ 调用LLM:                                                │
│ ├─→ 构建System Prompt                                  │
│ │   • 角色定位: "你是一个友好的QQ机器人"                 │
│ │   • 回复规则: 简洁、自然、不啰嗦                       │
│ │   • 上下文信息: 插入记忆、检索结果、对话历史            │
│ │                                                      │
│ ├─→ 构建User Prompt                                    │
│ │   • 用户当前的消息内容                                 │
│ │   • 图片说明(如果有)                                   │
│ │                                                      │
│ └─→ 请求LLM API                                        │
│     • 模型: 配置的主模型(如gpt-4-turbo)                 │
│     • 超时: 30秒                                        │
│     • 返回: LLM生成的回复文本                            │
│                                                        │
│ 解析LLM输出为动作列表:                                   │
│ actions = [                                            │
│   {"type": "text", "content": "这是回复文本"},          │
│   {"type": "sticker", "sticker_id": "xxx"},           │
│   ...                                                  │
│ ]                                                      │
│                                                        │
│ 可能的动作类型:                                          │
│ • text: 文本消息                                        │
│ • sticker: 表情包                                       │
│ • image: 图片                                          │
│ • reply: 引用回复                                       │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤13: 选择表情包 (如果需要)                            │
│                                                        │
│ StickerSelector.select()                               │
│                                                        │
│ • 分析对话意图(无奈/开心/调侃等)                         │
│ • 从stickers表查询匹配的表情包                           │
│ • 过滤条件:                                             │
│   - is_enabled=True                                   │
│   - is_banned=False                                   │
│   - 不在冷却期(60秒内未使用过)                          │
│ • 按匹配度和使用统计排序                                 │
│ • 返回最合适的表情包ID                                   │
│ • 如果没有合适的,返回None                               │
└────────────┬───────────────────────────────────────────┘
             │
             ▼
┌────────────────────────────────────────────────────────┐
│ 步骤14: 分段发送动作 (模拟真人)                          │
│                                                        │
│ ActionSender.send_actions()                            │
│                                                        │
│ 对每个action:                                           │
│ ├─→ 添加随机延迟 (300-900毫秒)                         │
│ │   模拟打字时间,避免太快被识别为机器人                  │
│ │                                                      │
│ ├─→ 根据类型发送                                        │
│ │   • text → bot.send_message()                       │
│ │   • sticker → bot.send_message(image_segment)      │
│ │   • image → bot.send_message(image_segment)        │
│ │                                                      │
│ ├─→ 记录机器人消息                                      │
│ │   • 写入raw_messages (is_bot=True)                  │
│ │   • 用于对话历史完整性                                │
│ │                                                      │
│ ├─→ 记录表情包使用                                      │
│ │   如果是sticker:                                     │
│ │   • 写入sticker_usage表                             │
│ │   • 更新使用统计                                      │
│ │   • 用于个性化推荐                                    │
│ │                                                      │
│ └─→ 更新限流状态                                        │
│     • 更新last_sent_ts                                │
│     • 设置cooldown_until_ts                           │
│     • 增加recent_bot_msg_count                        │
│                                                        │
│ 发送完成 ✅                                             │
└────────────────────────────────────────────────────────┘
```

### 错误处理与降级策略

每个步骤都有异常处理:
- **非关键步骤失败**: 记录日志,继续执行后续步骤
- **关键步骤失败**(如LLM调用): 返回默认回复或不回复
- **数据库失败**: 重试3次,仍失败则放弃本次操作
- **Qdrant失败**: 跳过向量检索,仅使用记忆和摘要

---

## 数据库结构说明

### 10张核心表的关系图

```
┌─────────────────┐
│  UserProfile    │ ← 用户档案(QQ号为主键)
│  (用户基本信息)  │
└────────┬────────┘
         │ 1:N
         │
    ┌────▼──────────────┐
    │   Memory          │ ← 用户记忆(事实/偏好/习惯)
    │  (分层存储)        │
    └───────────────────┘

┌──────────────────┐
│   RawMessage     │ ← 所有消息记录(用户+机器人)
│  (消息历史)       │
└────────┬─────────┘
         │ 1:N
         │
    ┌────▼────────────┐
    │  MemoryEvidence │ ← 记忆证据(消息→记忆的链接)
    └─────────────────┘

┌──────────────────┐
│    Summary       │ ← 对话摘要(按场景+时间窗口)
│  (窗口摘要)       │
└──────────────────┘

┌──────────────────┐
│  MediaCache      │ ← 媒体缓存(图片说明/OCR)
│  (图片处理结果)   │
└──────────────────┘

┌──────────────────┐
│  BotRateLimit    │ ← 限流状态(按场景)
│  (回复频率控制)   │
└──────────────────┘

┌──────────────────┐       ┌────────────────────┐
│    Sticker       │ ←─┐   │ StickerCandidate   │
│  (表情包正式库)   │   └───│  (候选池)          │
└────────┬─────────┘       └────────────────────┘
         │ 1:N
         │
    ┌────▼────────────┐
    │ StickerUsage    │ ← 使用记录(统计分析)
    └─────────────────┘

┌──────────────────┐
│   IndexJob       │ ← 索引任务队列(向量化/OCR)
│  (后台任务)       │
└──────────────────┘
```

### 表详细说明

#### 1. UserProfile - 用户档案表
```sql
主键: qq_id (QQ号)

字段说明:
- effective_count: 有效发言数(触发记忆提取的计数器)
- next_memory_at: 下次记忆提取的阈值(默认50)
- last_memory_msg_id: 上次处理到的消息ID(避免重复)
- pending_memory: 是否有待处理的记忆任务(布尔值)
- created_at/updated_at: 创建和更新时间

使用场景:
• 用户每发一条有效消息,effective_count+1
• 达到next_memory_at时,设置pending_memory=True
• 后台worker提取记忆后,清除pending_memory

数据增长: 缓慢(每个用户一行,随用户数增长)
清理策略: 长期不活跃用户可归档
```

#### 2. RawMessage - 原始消息表
```sql
主键: id (自增ID)
索引: (qq_id, timestamp), (scene_type, scene_id, timestamp)

字段说明:
- scene_type/scene_id: 场景标识(群聊/私聊)
- timestamp: 消息时间戳(秒)
- msg_type: 消息类型(text/image/mixed)
- content: 归一化后的文本内容
- raw_ref: 原始引用(图片URL等)
- reply_to_msg_id: 回复的消息ID
- mentioned_bot: 是否@机器人
- is_effective: 是否有效消息
- is_bot: 是否机器人发送

使用场景:
• 所有消息都记录(包括机器人自己的)
• 用于记忆提取、摘要生成、历史查询
• 提供完整的对话上下文

数据增长: 快速(每条消息一行)
清理策略: 定期删除3个月前的消息(保留摘要即可)
```

#### 3. Memory - 记忆表
```sql
主键: id (自增ID)
索引: (qq_id, tier, updated_at), (qq_id, type, updated_at)

字段说明:
- tier: 记忆层级(active/archive/core)
- type: 记忆类型(fact/preference/habit/experience)
- content: 记忆内容文本
- confidence: 置信度(0.0-1.0)
- status: 状态(active/archived/deleted)
- visibility: 可见性(global/scene/private)
- scope_scene_id: 作用域场景(仅某群可见)
- ttl_days: 生存时间(天,可选)
- source_memory_ids: 来源记忆ID(合并时记录)

使用场景:
• LLM从对话中提取的结构化信息
• 提供个性化上下文
• 支持长期对话连贯性

数据增长: 中等(每用户约20-100条)
清理策略:
• 定期归档active→archive
• 低置信度记忆自动删除
• 超过ttl_days的自动清理
```

#### 4. Summary - 摘要表
```sql
主键: id (自增ID)
索引: (scene_type, scene_id, window_end_ts)

字段说明:
- window_start_ts/window_end_ts: 窗口时间范围
- summary_text: LLM生成的摘要文本
- topic_state_json: 话题状态(JSON,可选)

使用场景:
• 每20条消息或15分钟生成一次
• 压缩大量消息为简短摘要
• 提供给LLM作为远期上下文

数据增长: 中等(每个活跃群每天几十条)
清理策略: 保留最近30天,旧的删除
```

#### 5. IndexJob - 索引任务表
```sql
主键: job_id (自增ID)
索引: (status, next_retry_ts)

字段说明:
- item_type: 任务类型(msg_chunk/ocr/memory/sticker)
- ref_id: 引用ID(消息ID/表情包ID等)
- payload_json: 任务数据(JSON格式)
- status: 状态(pending/processing/completed/failed)
- retry_count: 重试次数
- next_retry_ts: 下次重试时间(用于延迟重试)

使用场景:
• 异步向量化任务(避免阻塞主流程)
• 后台worker认领pending任务处理
• 失败自动重试(指数退避)

数据增长: 快速(每条消息/图片一个任务)
清理策略:
• completed任务定期删除
• failed任务超过7天删除
```

---

## 关键模块详解

### 1. 记忆系统 (Memory)

#### 记忆提取流程
```
触发条件: effective_count达到阈值 OR 空闲2分钟
    │
    ▼
┌─获取最近消息────────────────────────┐
│ • 从last_memory_msg_id开始         │
│ • 取最多100条消息                  │
│ • 包含上下文(前10条重叠)           │
└─────────┬──────────────────────────┘
          │
          ▼
┌─调用LLM提取────────────────────────┐
│ System Prompt:                    │
│ "从以下对话中提取用户信息:         │
│  - 个人信息(职业/年龄/地域等)      │
│  - 偏好(喜欢/不喜欢)               │
│  - 习惯(作息/行为模式)             │
│  - 重要经历"                       │
│                                   │
│ LLM返回: JSON格式的记忆列表        │
│ [                                 │
│   {                               │
│     "type": "fact",               │
│     "content": "用户是程序员",     │
│     "confidence": 0.9             │
│   },                              │
│   ...                             │
│ ]                                 │
└─────────┬──────────────────────────┘
          │
          ▼
┌─写入数据库─────────────────────────┐
│ • tier设为"active"                │
│ • 记录source_memory_ids           │
│ • 链接evidence(消息ID)            │
│ • 更新last_memory_msg_id          │
└───────────────────────────────────┘
```

#### 记忆浓缩(每天凌晨3点执行)
```
目的: 合并相似记忆,保持记忆库精简

┌─查询用户的active记忆───────────────┐
│ • 按用户分组                       │
│ • 每用户取所有active记忆           │
└─────────┬──────────────────────────┘
          │
          ▼
┌─调用LLM浓缩────────────────────────┐
│ "将以下记忆合并,去重,保留关键信息:" │
│                                   │
│ 输入: 20条active记忆               │
│ 输出: 5-10条浓缩后的core记忆       │
└─────────┬──────────────────────────┘
          │
          ▼
┌─更新数据库─────────────────────────┐
│ • 浓缩后的记忆 → tier="core"       │
│ • 原记忆 → tier="archive"         │
│ • 记录source_memory_ids追溯       │
└───────────────────────────────────┘
```

### 2. 表情包系统 (Stickers)

#### 表情包偷取流程
```
群里发了一张图片
    │
    ▼
┌─下载图片到临时目录─────────────────┐
│ • URL → 本地文件                  │
│ • assets/media/tmp/xxx.img        │
└─────────┬──────────────────────────┘
          │
          ▼
┌─计算指纹───────────────────────────┐
│ • SHA256: 文件哈希                │
│ • PHash: 感知哈希(识别相似图)      │
│ • OCR: 识别图中文字                │
│ • Fingerprint: phash+ocr的组合    │
└─────────┬──────────────────────────┘
          │
          ▼
┌─检查是否已存在─────────────────────┐
│ • 在stickers表中查fingerprint     │
│ • 在sticker_candidates中查        │
└─────────┬──────────────────────────┘
          │
          ├─→ 已存在 → 跳过
          │
          └─→ 不存在 ↓
              │
              ▼
        ┌─加入候选池──────────────────┐
        │ • 创建StickerCandidate记录 │
        │ • seen_count = 1           │
        │ • status = "pending"       │
        │ • 保存sample_file_path     │
        └─────────┬──────────────────┘
                  │
            (下次再见到相同图)
                  │
                  ▼
        ┌─更新候选记录────────────────┐
        │ • seen_count += 1          │
        │ • 更新last_seen_ts         │
        │ • 添加source_qq_id         │
        └─────────┬──────────────────┘
                  │
         (seen_count >= 阈值,如3次)
                  │
                  ▼
        ┌─晋升为正式表情包────────────┐
        │ • 移动文件到stickers目录    │
        │ • 创建Sticker记录           │
        │ • is_enabled = True        │
        │ • 删除候选记录              │
        │ • 调用LLM生成tags/intents  │
        └─────────────────────────────┘
```

#### 表情包选择流程
```
需要发送表情包
    │
    ▼
┌─分析对话意图───────────────────────┐
│ • 从用户消息推断情绪/意图          │
│ • 如"无奈"、"开心"、"调侃"等      │
│ • 可以调用LLM辅助判断              │
└─────────┬──────────────────────────┘
          │
          ▼
┌─查询匹配的表情包───────────────────┐
│ WHERE:                            │
│ • is_enabled = True               │
│ • is_banned = False               │
│ • intents LIKE '%意图%'           │
│ • NOT in cooldown(60秒内未用)     │
│                                   │
│ ORDER BY:                         │
│ • 意图匹配度                       │
│ • 使用频率(越常用越好)             │
│ • 随机因子(避免总是同一个)         │
└─────────┬──────────────────────────┘
          │
          ▼
┌─返回最佳表情包─────────────────────┐
│ • 如果有匹配: 返回sticker_id      │
│ • 如果没有: 返回None               │
└───────────────────────────────────┘
```

### 3. 向量检索 (Retrieval)

#### 检索流程
```
用户发送: "上次我们聊的那个话题怎么样了?"
    │
    ▼
┌─构建检索查询─────────────────────────┐
│ query_text = "上次我们聊的那个话题" │
│ + 用户基本信息                      │
└─────────┬────────────────────────────┘
          │
          ▼
┌─生成查询向量─────────────────────────┐
│ • 调用Embedder API                  │
│ • 输入: query_text                  │
│ • 输出: 2048维向量(一串浮点数)       │
└─────────┬────────────────────────────┘
          │
          ▼
┌─Qdrant向量检索───────────────────────┐
│ • search(                            │
│     collection="messages",           │
│     query_vector=向量,               │
│     limit=5  # top-5                │
│   )                                  │
│                                      │
│ • Qdrant返回最相似的5条消息          │
│ • 每条包含: 消息内容 + 相似度分数    │
└─────────┬────────────────────────────┘
          │
          ▼
┌─格式化检索结果───────────────────────┐
│ rag_snippets = [                     │
│   {                                  │
│     "content": "之前聊的是xxx",      │
│     "score": 0.87,                   │
│     "timestamp": 1234567890          │
│   },                                 │
│   ...                                │
│ ]                                    │
│                                      │
│ • 截断过长文本(最多120字符)          │
│ • 按相似度排序                       │
└──────────────────────────────────────┘
```

### 4. 心流模式 (Flow Mode) 🆕

#### 什么是心流模式?

心流模式是一种**智能回复决策系统**,使用轻量级nano模型来判断是否应该回复当前消息。相比传统的概率回复,心流模式能够:
- **理解对话语境**: 不再是简单的概率判断,而是真正理解对话内容
- **智能参与时机**: 知道什么时候该说话,什么时候该保持沉默
- **视觉理解能力**: 支持多模态输入,可以"看懂"图片内容来决策
- **提升对话质量**: 避免在不合适的时机打断对话

#### 配置说明

```toml
# ===== Nano模型配置 =====
nano_llm_base_url = "https://api.siliconflow.cn/v1"
nano_llm_api_key = "sk-..."
nano_llm_model = "THUDM/GLM-4.1V-9B-Thinking"  # 支持视觉的nano模型
nano_llm_timeout = 30.0

# ===== 心流模式开关 =====
flow_mode_enabled = true  # 启用心流模式

# ===== 心流模式参数 =====
flow_mode_check_probability = 0.8  # 概率抽样(80%的消息会调用nano判断)
flow_mode_directed_cooldown = 5.0  # @机器人后的冷却时间(秒)
flow_mode_undirected_cooldown = 15.0  # 主动回复后的冷却时间(秒)
```

#### 心流模式决策流程

```
收到新消息
    │
    ▼
┌─步骤1: 冷却检查────────────────────────┐
│ • 检查距离上次回复的时间               │
│ • 冷却中 → 直接返回False(不回复)      │
│ • 未冷却 → 继续                        │
└─────────┬──────────────────────────────┘
          │
          ▼
┌─步骤2: directed_to_bot检查────────────┐
│ • 是否@机器人?                         │
│ • 是否私聊?                            │
│ • 是否回复机器人消息?                  │
│                                        │
│ 如果是 → 必回(但仍受冷却限制)          │
│ 如果否 → 继续后续判断                  │
└─────────┬──────────────────────────────┘
          │
          ▼
┌─步骤3: 短路规则快速判断────────────────┐
│                                        │
│ 🔴 纯表情/emoji消息:                   │
│    • 检测消息是否只包含表情符号         │
│    • 如"😂😂😂"、"👍"等              │
│    → 不回复(避免无意义对话)            │
│                                        │
│ 🔴 过短消息:                           │
│    • 去除空白后<3个字符                │
│    • 如"哦"、"嗯"、"好"                │
│    → 不回复(太短无法判断意图)          │
│                                        │
│ 🟢 明显提问:                           │
│    • 包含"吗"、"?"、"什么"等关键词     │
│    • 如"你在吗?"、"这是什么?"          │
│    → 直接回复(明确的问题应该回答)      │
│                                        │
│ 如果命中短路规则 → 直接返回结果         │
│ 否则 → 继续nano判断                    │
└─────────┬──────────────────────────────┘
          │
          ▼
┌─步骤4: 概率抽样────────────────────────┐
│ • 生成随机数 random.random()           │
│ • 如果 < check_probability (80%)       │
│   → 调用nano模型                       │
│ • 否则 → 返回False(减少API调用)        │
│                                        │
│ 目的: 在成本和效果间平衡               │
└─────────┬──────────────────────────────┘
          │ 通过概率抽样
          ▼
┌─步骤5: 并发控制────────────────────────┐
│ • 使用Semaphore(3)限制并发             │
│ • 尝试获取令牌(0.001秒超时)            │
│ • 获取成功 → 继续调用nano              │
│ • 获取失败 → 返回False(过载保护)       │
└─────────┬──────────────────────────────┘
          │ 获得令牌
          ▼
┌─步骤6: 获取对话上下文──────────────────┐
│ • 从raw_messages表查询最近10条消息     │
│ • 按时间倒序排列                       │
│ • 精确排除当前消息(基于msg_id)         │
│ • 格式化为对话列表:                    │
│   ["USER(12345): 今天天气真好",       │
│    "BOT: 是啊,适合出去玩",            │
│    "USER(67890): 要不要一起?"]        │
└─────────┬──────────────────────────────┘
          │
          ▼
┌─步骤7: 构建nano请求 (支持多模态)──────┐
│                                        │
│ 🎨 纯文本消息:                         │
│ {                                      │
│   "role": "system",                   │
│   "content": "你是语影,根据对话判断..." │
│ },                                     │
│ {                                      │
│   "role": "user",                     │
│   "content": "scene_type: group       │
│               directed_to_bot: false   │
│               recent_messages:         │
│               - xxx                    │
│               current_message: xxx"    │
│ }                                      │
│                                        │
│ 🎨 多模态消息(包含图片):               │
│ {                                      │
│   "role": "user",                     │
│   "content": [                        │
│     {                                  │
│       "type": "text",                 │
│       "text": "scene_type: group..."  │
│     },                                 │
│     {                                  │
│       "type": "image_url",            │
│       "image_url": {                  │
│         "url": "https://..."          │
│       }                                │
│     },                                 │
│     {                                  │
│       "type": "text",                 │
│       "text": "image_caption: ..."    │
│     }                                  │
│   ]                                    │
│ }                                      │
│                                        │
│ 关键特性:                              │
│ • 使用OpenAI Vision API格式            │
│ • 图片URL + caption双重信息            │
│ • nano模型可"看懂"图片内容             │
│ • 最多支持2张图片                      │
└─────────┬──────────────────────────────┘
          │
          ▼
┌─步骤8: 调用nano LLM───────────────────┐
│ • 模型: THUDM/GLM-4.1V-9B-Thinking    │
│ • temperature: 0.2 (稳定但有变化)     │
│ • 超时: 30秒                           │
│ • 期望输出: "yes" 或 "no"             │
│                                        │
│ nano分析:                              │
│ • 对话语境(最近10条消息)               │
│ • 当前消息内容                         │
│ • 图片内容(如果有)                     │
│ • 机器人角色和性格                     │
│                                        │
│ 判断维度:                              │
│ • 对话连贯性                           │
│ • 回复的必要性                         │
│ • 话题相关性                           │
│ • 语影的性格特点                       │
└─────────┬──────────────────────────────┘
          │
          ▼
┌─步骤9: 解析nano输出───────────────────┐
│ • 提取回复文本中的yes/no               │
│ • 支持多种格式:                        │
│   - "yes" / "no"                      │
│   - "YES" / "NO"                      │
│   - "回答: yes"                        │
│   - "决定: no"                         │
│   - "我选择yes"                        │
│                                        │
│ 解析结果:                              │
│ • "yes" → 返回True (应该回复)         │
│ • "no" → 返回False (不应回复)         │
│ • 无法解析 → 返回None (保守不回复)    │
└─────────┬──────────────────────────────┘
          │
          ▼
┌─步骤10: 释放并发令牌──────────────────┐
│ • Semaphore.release()                 │
│ • 允许下一个nano调用                   │
└─────────┬──────────────────────────────┘
          │
          ▼
    返回决策结果
```

#### 多模态支持详解

心流模式的一大亮点是**多模态支持**,能够理解图片内容:

**场景1: 纯文本消息**
```
用户: "今天天气真好"
nano看到: 纯文本上下文
决策: 可能不回(非问题,无@)
```

**场景2: 纯图片消息**
```
用户: [发送一张猫咪图片]
nano看到:
- 图片URL (实际看到猫咪图像)
- caption: "一只橘猫在晒太阳"
决策: 可能回复(图片有趣,可以互动)
```

**场景3: 图文混合消息**
```
用户: "看这个" + [图片]
nano看到:
- 文本: "看这个"
- 图片内容
- caption信息
决策: 很可能回复(明显希望得到反馈)
```

#### 性能优化

1. **短路规则**: 纯表情、过短消息直接跳过,不调用nano
2. **概率抽样**: 80%的消息才调用nano,降低API成本
3. **并发控制**: Semaphore(3)限制同时最多3个nano调用
4. **上下文限制**: 只取最近10条消息,控制token消耗
5. **图片复用**: 提前获取图片URL,避免重复调用`bot.get_image()`

#### 成本分析

相比传统模式:
- **优势**: 更智能,对话质量更高,减少无意义回复
- **成本**: 每次判断约100-300 tokens (nano模型较便宜)
- **平衡**: 通过概率抽样和短路规则控制调用频率

推荐配置:
- 活跃群聊: `check_probability = 0.8` (高质量判断)
- 普通群聊: `check_probability = 0.5` (节省成本)
- 测试环境: `check_probability = 1.0` (完全判断,便于观察)

#### 心流模式 vs 传统模式对比

| 维度 | 传统模式 | 心流模式 |
|-----|---------|---------|
| **决策方式** | 随机概率(15%) | nano模型智能判断 |
| **理解能力** | 无上下文理解 | 理解对话语境 |
| **图片支持** | 不支持 | 支持视觉理解 |
| **回复质量** | 可能不合时宜 | 更自然,更合适 |
| **API成本** | 低(无额外调用) | 中等(nano模型) |
| **配置复杂度** | 简单(只需概率) | 中等(需配置nano) |
| **适用场景** | 低频对话,成本敏感 | 高质量对话,体验优先 |

---

## 配置说明

### 必须配置的项目

```toml
[yuying_chameleon]

# ===== 必填配置 =====

# LLM API配置(必须)
openai_api_key = "sk-..." # OpenAI API密钥
openai_model = "gpt-4-turbo" # 使用的模型

# Embedding配置(如果与LLM相同,会自动复用)
embedder_api_key = "sk-..." # 可选,默认复用openai_api_key
embedder_model = "text-embedding-3-small"

# ===== 可选配置 =====

# 数据库(默认值通常够用)
database_url = "sqlite+aiosqlite:///data/yuying.db"

# Qdrant向量库(默认连接本地)
qdrant_host = "localhost"
qdrant_port = 6333

# ===== 回复策略配置 =====

# 传统模式配置(flow_mode_enabled=false时生效)
group_reply_probability = 0.15 # 群聊主动回复概率(15%)
group_cooldown_seconds = 60 # 群聊冷却时间(秒)

# 心流模式配置(flow_mode_enabled=true时生效) 🆕
flow_mode_enabled = true # 启用心流模式
flow_mode_check_probability = 0.8 # 概率抽样(80%的消息会调用nano判断)
flow_mode_directed_cooldown = 5.0 # @机器人后的冷却时间(秒)
flow_mode_undirected_cooldown = 15.0 # 主动回复后的冷却时间(秒)

# Nano模型配置(心流模式必须) 🆕
nano_llm_base_url = "https://api.siliconflow.cn/v1"
nano_llm_api_key = "sk-..."
nano_llm_model = "THUDM/GLM-4.1V-9B-Thinking" # 支持视觉的nano模型
nano_llm_timeout = 30.0

# 记忆配置
memory_effective_count_threshold = 50 # 多少条消息后提取记忆
```

### 配置文件位置

优先级(从高到低):
1. 环境变量 `YUYING_CONFIG_TOML`
2. 当前工作目录 `configs/config.toml`
3. 项目根目录 `configs/config.toml`

### 使用火山方舟(国内LLM)

```toml
[yuying_chameleon]
api_provider = "ark" # 指定使用火山方舟

openai_api_key = "你的火山方舟API_KEY"
openai_model = "doubao-pro-32k"
openai_base_url = "https://ark.cn-beijing.volces.com/api/v3"

# embedding也用火山方舟
embedder_model = "doubao-embedding"
```

---

## 常见问题

### Q1: 机器人不回复消息怎么办?

检查步骤:
1. **查看日志**: `nb run --reload`,看是否有报错
2. **检查配置**: 确认`openai_api_key`已正确配置
3. **检查限流**:
   - 私聊必定回复
   - 群聊需要@机器人或随机触发
   - 检查是否在冷却期(60秒内已回复)
4. **检查LLM**: 手动测试API密钥是否有效

### Q2: 回复很慢怎么办?

可能原因:
1. **LLM响应慢**: 换更快的模型(如gpt-3.5-turbo)
2. **向量检索慢**:
   - 检查Qdrant是否正常运行
   - 可以降低`retrieval_topk`(默认5)
3. **图片处理慢**:
   - 关闭OCR: `media_enable_ocr = false`
   - 或使用更快的视觉模型

### Q3: 数据库文件在哪里?

默认位置: `项目根目录/data/yuying.db`

可以在配置中修改:
```toml
database_url = "sqlite+aiosqlite:///你的路径/yuying.db"
```

### Q4: 如何清空数据重新开始?

方法1: 删除数据库文件
```bash
rm data/yuying.db
# 重启机器人会自动重建
```

方法2: 重建向量库
```toml
qdrant_recreate_collections = true
```
**警告**: 会删除所有向量数据!

### Q5: 表情包从哪里来?

两个来源:
1. **本地表情包**: 放在`assets/stickers/`目录
   - 启动时自动扫描导入
   - 支持png/jpg/gif等格式

2. **自动偷取**: 群聊中发的图片
   - 出现3次以上自动收录
   - 需要群聊功能开启

### Q6: 记忆什么时候提取?

触发条件(满足任一):
1. 用户发送50条有效消息后
2. 对话停止2分钟后(空闲时提取)

可以调整:
```toml
memory_effective_count_threshold = 50 # 阈值
memory_idle_seconds = 120 # 空闲时间(秒)
```

### Q7: 如何让机器人更活跃/更安静?

调整群聊回复概率:
```toml
# 更活跃
group_reply_probability = 0.3 # 30%概率主动回复

# 更安静
group_reply_probability = 0.05 # 5%概率主动回复

# 完全被动(只响应@)
group_reply_probability = 0.0
```

### Q8: 消耗会很大吗?

成本分析:
- **LLM调用**: 每次回复约1000-2000 tokens
- **Embedding**: 每条消息约50-100 tokens
- **图片处理**: 需要视觉模型(成本较高)
- **心流模式nano调用** 🆕: 每次判断约100-300 tokens

优化建议:
1. 使用便宜模型处理简单任务
   ```toml
   cheap_llm_model = "gpt-3.5-turbo"
   ```
2. 关闭不需要的功能
   ```toml
   media_enable_ocr = false # 关闭OCR
   ```
3. 降低向量检索量
   ```toml
   retrieval_topk = 3 # 减少检索数量
   ```
4. 调整心流模式参数 🆕
   ```toml
   flow_mode_check_probability = 0.5 # 降低nano调用频率
   ```

### Q9: 什么是心流模式?应该开启吗? 🆕

**什么是心流模式?**
心流模式使用轻量级nano模型智能判断是否应该回复每条消息,相比传统的随机概率回复更智能。

**优势:**
- ✅ 理解对话语境,知道什么时候该说话
- ✅ 支持视觉理解,可以"看懂"图片内容
- ✅ 避免无意义回复,提升对话质量
- ✅ 让机器人参与更自然,不会显得突兀

**劣势:**
- ❌ 需要额外配置nano模型API
- ❌ 每次判断会增加一点成本(但nano模型很便宜)
- ❌ 多一次API调用,略微增加延迟

**建议:**
- 🎯 **追求对话质量** → 开启心流模式
- 💰 **成本敏感** → 使用传统模式
- 🧪 **测试环境** → 开启心流模式,便于观察效果

### Q10: 心流模式支持哪些nano模型? 🆕

**推荐模型:**
1. **THUDM/GLM-4.1V-9B-Thinking** (推荐)
   - 支持视觉理解(多模态)
   - 性能好,价格便宜
   - 可以"看懂"图片内容

2. **gpt-4o-mini** (备选)
   - OpenAI官方模型
   - 支持视觉
   - 价格稍贵但质量稳定

3. **其他OpenAI兼容模型**
   - 只要支持Chat Completions API即可
   - 如果需要图片理解,必须支持Vision API

**配置示例:**
```toml
# 使用GLM(推荐)
nano_llm_base_url = "https://api.siliconflow.cn/v1"
nano_llm_model = "THUDM/GLM-4.1V-9B-Thinking"

# 使用OpenAI
nano_llm_base_url = "https://api.openai.com/v1"
nano_llm_model = "gpt-4o-mini"
```

### Q11: 心流模式的图片支持如何工作? 🆕

**工作流程:**
1. 用户发送包含图片的消息
2. 系统获取图片URL和caption(图片说明)
3. 将图片以OpenAI Vision API格式发送给nano模型
4. nano模型"看到"图片内容,理解图像含义
5. 基于图片内容和对话语境判断是否回复

**示例场景:**
```
用户: [发送一张猫咪图片]
nano看到:
- 图片: 一只橘猫在晒太阳
- caption: "橘猫,晒太阳,慵懒"
决策: 可能回复 → "好可爱的橘猫!看起来很惬意呀~"
```

**注意事项:**
- 最多支持2张图片(受`_collect_image_inputs`限制)
- nano模型必须支持Vision API
- 纯文本消息仍按原有方式处理

### Q12: 如何调试心流模式? 🆕

**查看决策过程:**
```bash
# 启动时开启调试日志
nb run --log-level DEBUG
```

关键日志:
```
心流模式 nano 模型调用（images=0）  # 查看是否有图片
心流模式: 短路规则命中 - 纯表情  # 短路规则
心流模式: nano返回yes  # nano判断结果
```

**常见问题排查:**
1. **总是不回复** → 检查`flow_mode_check_probability`是否太低
2. **总是回复** → 检查短路规则是否正常工作
3. **图片不生效** → 检查nano模型是否支持Vision API
4. **调用失败** → 检查nano_llm_api_key和base_url配置

**性能监控:**
```python
# 可以在日志中看到:
# - nano调用次数
# - 短路规则命中率
# - 平均决策时间
# - 并发控制情况
```

---

## 结语

这份文档详细介绍了YuYing-Chameleon的运行逻辑。如果你是编程新手,建议:

1. **从配置开始**: 先把机器人跑起来
2. **观察日志**: 看看每一步在做什么
3. **查看数据库**: 用SQLite工具查看表结构和数据
4. **逐步学习**: 先理解主流程,再深入各个模块

项目地址: https://github.com/你的仓库地址
文档生成时间: 2025年
